{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "617e2cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n",
      "Index(['PhraseId', 'SentenceId', 'Phrase', 'Sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#read datas\n",
    "import pandas as pd\n",
    "dir_data_all = '/Users/apple/Desktop/data/sentiment-analysis-on-movie-reviews/train.tsv'\n",
    "data_all = pd.read_csv(dir_data_all, sep='\\t')\n",
    "print(data_all.shape)\n",
    "print(data_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "810feb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93636,)\n",
      "(31212,)\n"
     ]
    }
   ],
   "source": [
    "#split training datasets, testing datasets and evaluating datasets\n",
    "#make sure that the size of testing datasets is equal to that of evaluating datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_all = data_all['Phrase']\n",
    "y_all = data_all['Sentiment']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape) #PhraseId Phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9767b0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93636, 15181)\n",
      "(31212, 15181)\n"
     ]
    }
   ],
   "source": [
    "#get the corpus matrix\n",
    "#return a tuple(Index of Phrase, Index of representation of the word in the dictionary)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "x_train_counts = count_vect.fit_transform(x_train)\n",
    "x_test_counts = count_vect.transform(x_test)\n",
    "print(x_train_counts.shape)\n",
    "print(x_test_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58840228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93636, 15181)\n",
      "(31212, 15181)\n"
     ]
    }
   ],
   "source": [
    "#word-level tfidf\n",
    "#use TF to evaluate the frequency of a word appearing in one article(sparse)\n",
    "#TF = the frequency of a particular word / the whole word in the passage\n",
    "#searching word is more important\n",
    "#the more it occurs in the passage, the more important it is\n",
    "#when there are many conjuctions, it is difficult to distinguish between them\n",
    "#use IDF to penalize those occuring too much in the passage(how, to, what),reconcling TF\n",
    "#IDF = log(number of all passages / (number of passages containing the word + 1))\n",
    "#if one word occurs too much in all passages, it must carry less information\n",
    "#TF-IDF = TF * IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_transformer = TfidfVectorizer(analyzer='word', max_features=50000)\n",
    "tfidf_transformer.fit(x_train)\n",
    "x_train_tfidf_word = tfidf_transformer.transform(x_train)\n",
    "x_test_tfidf_word = tfidf_transformer.transform(x_test)\n",
    "print(x_train_tfidf_word.shape)\n",
    "print(x_test_tfidf_word.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fe58a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93636, 50000) (31212, 50000)\n"
     ]
    }
   ],
   "source": [
    "#ngram-level tfidf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfVectorizer(analyzer='word', ngram_range=(2, 3), max_features=50000)\n",
    "tfidf_transformer.fit(x_train)\n",
    "x_train_tfidf_ngram = tfidf_transformer.transform(x_train)\n",
    "x_test_tfidf_ngram = tfidf_transformer.transform(x_test)\n",
    "print(x_train_tfidf_ngram.shape, x_test_tfidf_ngram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb2f7efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93636, 80362)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "train_features=x_train_counts\n",
    "test_features=x_test_counts\n",
    "\n",
    "train_features=hstack([x_train_counts, x_train_tfidf_word, x_train_tfidf_ngram])\n",
    "test_features=hstack([x_test_counts, x_test_tfidf_word, x_test_tfidf_ngram])\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "205bb6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(\n",
    "    random_state=0,\n",
    "    solver='sag',\n",
    "    multi_class='multinomial'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08d4c77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/opt/anaconda3/envs/mathcup/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', random_state=0, solver='sag')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_features, y_train = shuffle(train_features, y_train)\n",
    "clf.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "961c911c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6539792387543253\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predict = clf.predict(test_features)\n",
    "print(np.mean(predict==y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d51933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mathcup",
   "language": "python",
   "name": "mathcup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
